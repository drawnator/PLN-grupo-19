{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drawnator/PLN-grupo-19/blob/main/Grupo19_PLN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ferramenta Otimizadora De Aleatoriedade em senhas\n",
        "---\n",
        "Modelo de linguagem que auxilia a tornar senhas mais fortes, analisando a entrada e dando sugestões que tornariam a senha mais improvável de adivinhar.\n",
        "\n",
        "base de dados utilizada:\n",
        "[rockyou.txt](https://github.com/brannondorsey/naive-hashcat/releases/download/data/rockyou.txt)\n",
        "\n",
        "Assuntos:\n",
        "- Análise de frequência\n",
        "- Masked language model\n",
        "\n",
        "Tecnologias utilizadas:\n",
        "- Bert\n",
        "- RNN\n",
        "- Árvores de decisão\n",
        "- Senha aleatória"
      ],
      "metadata": {
        "id": "hX_YXyR6EBrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparando o ambiente de execução (imports necessários)"
      ],
      "metadata": {
        "id": "Vzuy8RtdHI4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, Dropout, SimpleRNN\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import Sequence\n"
      ],
      "metadata": {
        "id": "_RQAO_HBKYuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparando os dados"
      ],
      "metadata": {
        "id": "rPVu61au2S4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RECOMENDO FORTEMENTE BAIXAR E ARRASTAR MANUALMENTE ATÉ ARTIGOS, ISSO AQUI DEMORA MT \\/\n",
        "url = \"https://github.com/brannondorsey/naive-hashcat/releases/download/data/rockyou.txt\"\n",
        "# response = requests.get(url)\n",
        "# data = response.text\n",
        "#..."
      ],
      "metadata": {
        "id": "eT4e-TD-2Was"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"rockyou.txt\", \"r\", encoding='latin-1') as f:\n",
        "  df = pd.DataFrame(f.readlines(), columns=['password'])"
      ],
      "metadata": {
        "id": "No5klVbO2nvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['password'] = df['password'].str.replace('\\n', '')"
      ],
      "metadata": {
        "id": "zUtJslgF2pY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if not os.path.exists(\"rockyou.csv\"):\n",
        "#   df.to_csv(\"rockyou.csv\")"
      ],
      "metadata": {
        "id": "S4nnAppL2t0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20iT9wPq2sZp",
        "outputId": "685b4d74-3e9f-48e8-b7e6-f1c86a843f68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6874685, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Métodos de avaliar a qualidade de uma senha"
      ],
      "metadata": {
        "id": "rGigW6AgJasc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN\n",
        "\n",
        "Previsibilidade de caracteres, com base em uma parte da senha o quão fácil é prever o resto dela?\n"
      ],
      "metadata": {
        "id": "8WOA63DN2CmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenização\n",
        "\n",
        "Transformando os caracteres de uma senha em tokens para que eles estejam no formato adequado para o processamento."
      ],
      "metadata": {
        "id": "0f0dF3CQNf5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_chars = sorted(list(set(''.join(df['password']))))\n",
        "char_to_int = {char: i for i, char in enumerate(all_chars)}\n",
        "int_to_char = {i: char for char, i in char_to_int.items()}"
      ],
      "metadata": {
        "id": "fVY6zfNDQyRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_int['[MASK]'] = len(char_to_int)\n",
        "char_to_int['[CLS]'] = len(char_to_int)\n",
        "char_to_int['[SEP]'] = len(char_to_int)\n",
        "char_to_int['[PAD]'] = len(char_to_int)\n",
        "int_to_char = {i: char for char, i in char_to_int.items()}"
      ],
      "metadata": {
        "id": "i0oOgtFOT93d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNTokenizer:\n",
        "  def __init__(self, char_to_int,int_to_char,max_length = 32):\n",
        "    self.char_to_int = char_to_int\n",
        "    self.int_to_char = int_to_char\n",
        "    self.mask_token_id = char_to_int['[MASK]']\n",
        "    self.cls_token_id = char_to_int['[CLS]']\n",
        "    self.sep_token_id = char_to_int['[SEP]']\n",
        "    self.pad_token_id = char_to_int['[PAD]']\n",
        "    self.max_length = max_length\n",
        "    self.vocab_size = len(char_to_int)\n",
        "\n",
        "  def __call__(self,text):\n",
        "    token = []\n",
        "    for i in range(self.max_length):\n",
        "      if (i < len(text)):\n",
        "        token.append(char_to_int[text[i]])\n",
        "      else:\n",
        "        token.append(char_to_int['[PAD]'])\n",
        "    return token"
      ],
      "metadata": {
        "id": "FVDjp6dwT5f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnntokenizer = RNNTokenizer(char_to_int,int_to_char)"
      ],
      "metadata": {
        "id": "sMTlDRQeUAa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNDataloader(Sequence):\n",
        "  def __init__(self,dataframe,tokenizer,batch_size=100):\n",
        "    self.dataframe = dataframe\n",
        "    self.tokenizer = tokenizer\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def mask_and_tokens(self,password):\n",
        "      i = np.random.randint(1, min(len(password),self.tokenizer.max_length))\n",
        "      tokens = self.tokenizer(password)\n",
        "      input_seq = tokens[:i]\n",
        "      label = tokens[i]\n",
        "      input_seq += [self.tokenizer.mask_token_id]\n",
        "      input_seq += [self.tokenizer.pad_token_id] * (self.tokenizer.max_length - len(input_seq))\n",
        "      return input_seq,label\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataframe) // self.batch_size\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    batch = self.dataframe[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "    batch_inputs = []\n",
        "    batch_labels = []\n",
        "    for password in batch:\n",
        "      input_seq, label = self.mask_and_tokens(password)\n",
        "      batch_inputs.append(input_seq)\n",
        "      batch_labels.append(label)\n",
        "    return np.array(batch_inputs), np.array(batch_labels)"
      ],
      "metadata": {
        "id": "-vnhBPtAAx97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = RNNDataloader(df['password'],rnntokenizer)"
      ],
      "metadata": {
        "id": "cKoiosZFA06E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"password\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NNvMtosUBk2J",
        "outputId": "ae5fb498-30a8-471f-f0ad-0f4581f313c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'123456'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader[0]"
      ],
      "metadata": {
        "id": "58BckWpOSTK2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb7709ee-0d4e-4541-b4b0-09828d2f452b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 18,  19,  20, ..., 212, 212, 212],\n",
              "        [ 18,  19,  20, ..., 212, 212, 212],\n",
              "        [ 18,  19,  20, ..., 212, 212, 212],\n",
              "        ...,\n",
              "        [ 77,  66,  86, ..., 212, 212, 212],\n",
              "        [ 78,  74,  68, ..., 212, 212, 212],\n",
              "        [ 81,  83, 209, ..., 212, 212, 212]]),\n",
              " array([22, 21, 25, 83, 87, 74, 24, 76, 23, 19, 68, 79, 72, 90, 90, 70, 18,\n",
              "        66, 90, 70, 18, 80, 17, 70, 72, 86, 85, 80, 70, 79, 79, 90, 70, 79,\n",
              "        83, 83, 85, 87, 90, 20, 85, 83, 69, 66, 70, 80, 77, 20, 86, 79, 79,\n",
              "        90, 70, 76, 70, 72, 90, 80, 90, 70, 73, 74, 74, 73, 66, 83, 77, 83,\n",
              "        66, 84, 69, 23, 73, 84, 78, 85, 67, 77, 87, 74, 79, 25, 85, 73, 66,\n",
              "        84, 80, 80, 86, 88, 81, 73, 83, 77, 77, 77, 77, 70, 70, 74]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dividindo os dados em conjuntos de treino e"
      ],
      "metadata": {
        "id": "GkaguFhoY-vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "def create_train_val_test_arrays(df, dataloader, tokenizer, test_size=0.2, val_size=0.5,):\n",
        "    train_df, temp_df = train_test_split(df, test_size=test_size, random_state=42)\n",
        "    val_df, test_df = train_test_split(temp_df, test_size=val_size, random_state=42)\n",
        "\n",
        "    train_dataloader = dataloader(train_df, tokenizer)\n",
        "    val_dataloader = dataloader(val_df, tokenizer)\n",
        "    test_dataloader = dataloader(test_df, tokenizer)\n",
        "\n",
        "    return train_dataloader, val_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "0bE3jvF_fxIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader,val_dataloader,test_dataloader = create_train_val_test_arrays(df[\"password\"], RNNDataloader, rnntokenizer)"
      ],
      "metadata": {
        "id": "2IHv8Tv8gndR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# defining a model\n",
        "TODO: modelo RNN mas train label usados no treinamento do bert, opções:\n",
        "- mudar modelo a baixo para fazer fine tunning do bert\n",
        "- mudar mask_tokens para gerar uma entrada e saida condizente com um problema RNN\n"
      ],
      "metadata": {
        "id": "zwoaQJ2obmui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://colab.research.google.com/drive/1mts5E3yAd1irLzS7Ei6UtwbG773C87DB?usp=sharing\n",
        "model = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=rnntokenizer.vocab_size,\n",
        "        output_dim=100,\n",
        "        input_shape=(rnntokenizer.max_length,)),\n",
        "    SimpleRNN(64, return_sequences=False),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(rnntokenizer.vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "M9EaU8RZc8cW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "aed4318e-61b3-4be4-f832-e61417ae8f1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:100: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m21,300\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m10,560\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m213\u001b[0m)            │        \u001b[38;5;34m13,845\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">21,300</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,560</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">213</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,845</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m49,865\u001b[0m (194.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,865</span> (194.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m49,865\u001b[0m (194.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,865</span> (194.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_dataloader,\n",
        "    validation_data=(val_dataloader),\n",
        "    epochs=3,\n",
        "    batch_size=256,\n",
        "    verbose=1)"
      ],
      "metadata": {
        "id": "3no88mxsehfx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d701d232-8764-4f1c-8627-0e7892757ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m  496/54997\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:31\u001b[0m 5ms/step - accuracy: 0.0701 - loss: 3.8505"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  ValueError: low >= high\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 248, in _finite_generator\n    yield self._standardize_batch(self.py_dataset[i])\n                                  ~~~~~~~~~~~~~~~^^^\n\n  File \"/tmp/ipython-input-3431407358.py\", line 24, in __getitem__\n    input_seq, label = self.mask_and_tokens(password)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/tmp/ipython-input-3431407358.py\", line 8, in mask_and_tokens\n    i = np.random.randint(1, min(len(password),self.tokenizer.max_length))\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"numpy/random/mtrand.pyx\", line 798, in numpy.random.mtrand.RandomState.randint\n\n  File \"numpy/random/_bounded_integers.pyx\", line 1334, in numpy.random._bounded_integers._rand_int64\n\nValueError: low >= high\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_4]]\n  (1) INVALID_ARGUMENT:  ValueError: low >= high\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 248, in _finite_generator\n    yield self._standardize_batch(self.py_dataset[i])\n                                  ~~~~~~~~~~~~~~~^^^\n\n  File \"/tmp/ipython-input-3431407358.py\", line 24, in __getitem__\n    input_seq, label = self.mask_and_tokens(password)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/tmp/ipython-input-3431407358.py\", line 8, in mask_and_tokens\n    i = np.random.randint(1, min(len(password),self.tokenizer.max_length))\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"numpy/random/mtrand.pyx\", line 798, in numpy.random.mtrand.RandomState.randint\n\n  File \"numpy/random/_bounded_integers.pyx\", line 1334, in numpy.random._bounded_integers._rand_int64\n\nValueError: low >= high\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_2381]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2202181877.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  ValueError: low >= high\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 248, in _finite_generator\n    yield self._standardize_batch(self.py_dataset[i])\n                                  ~~~~~~~~~~~~~~~^^^\n\n  File \"/tmp/ipython-input-3431407358.py\", line 24, in __getitem__\n    input_seq, label = self.mask_and_tokens(password)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/tmp/ipython-input-3431407358.py\", line 8, in mask_and_tokens\n    i = np.random.randint(1, min(len(password),self.tokenizer.max_length))\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"numpy/random/mtrand.pyx\", line 798, in numpy.random.mtrand.RandomState.randint\n\n  File \"numpy/random/_bounded_integers.pyx\", line 1334, in numpy.random._bounded_integers._rand_int64\n\nValueError: low >= high\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_4]]\n  (1) INVALID_ARGUMENT:  ValueError: low >= high\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 248, in _finite_generator\n    yield self._standardize_batch(self.py_dataset[i])\n                                  ~~~~~~~~~~~~~~~^^^\n\n  File \"/tmp/ipython-input-3431407358.py\", line 24, in __getitem__\n    input_seq, label = self.mask_and_tokens(password)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/tmp/ipython-input-3431407358.py\", line 8, in mask_and_tokens\n    i = np.random.randint(1, min(len(password),self.tokenizer.max_length))\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"numpy/random/mtrand.pyx\", line 798, in numpy.random.mtrand.RandomState.randint\n\n  File \"numpy/random/_bounded_integers.pyx\", line 1334, in numpy.random._bounded_integers._rand_int64\n\nValueError: low >= high\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_2381]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert"
      ],
      "metadata": {
        "id": "rfrxIdGw26Ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://colab.research.google.com/drive/1Suv_JhRhoYNOCHtrGQwqZQO18nMXHEfq?usp=sharing\n",
        "def mask_tokens(inputs, tokenizer, mlm_probability=0.10):\n",
        "    inputs = np.array(inputs)\n",
        "    labels = np.copy(inputs)\n",
        "\n",
        "    rand = np.random.rand(*inputs.shape)\n",
        "    mask_arr = (rand < mlm_probability)\n",
        "\n",
        "    special_tokens = [tokenizer.cls_token_id, tokenizer.sep_token_id]\n",
        "    for special_id in special_tokens:\n",
        "        mask_arr[inputs == special_id] = False\n",
        "\n",
        "    inputs[mask_arr] = tokenizer.mask_token_id\n",
        "\n",
        "    labels[~mask_arr] = 0\n",
        "\n",
        "    return inputs, labels"
      ],
      "metadata": {
        "id": "rt83RwRw2-77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train_val_test_datasets(df, tokenizer, test_size=0.10, val_size=0.15, batch_size=8,max=None):\n",
        "\n",
        "    if max:\n",
        "        df = df.head(max)\n",
        "\n",
        "    train_df, temp_df = train_test_split(df, test_size=test_size, random_state=42)\n",
        "    val_df, test_df = train_test_split(temp_df, test_size=val_size, random_state=42)\n",
        "\n",
        "    def df_to_dataset(dataframe, tokenizer, batch_size):\n",
        "        tokenized_passwords = dataframe['tokenized_password'].tolist()\n",
        "\n",
        "        masked_inputs = []\n",
        "        masked_labels = []\n",
        "        for tokens in tokenized_passwords:\n",
        "            inputs, labels = mask_tokens(tokens, tokenizer)\n",
        "            masked_inputs.append(inputs)\n",
        "            masked_labels.append(labels)\n",
        "\n",
        "        input_ids = tf.constant(masked_inputs, dtype=tf.int32)\n",
        "        labels = tf.constant(masked_labels, dtype=tf.int32)\n",
        "\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((input_ids, labels))\n",
        "        return dataset.shuffle(1000).batch(batch_size)\n",
        "\n",
        "    train_dataset = df_to_dataset(train_df, tokenizer, batch_size)\n",
        "    val_dataset = df_to_dataset(val_df, tokenizer, batch_size)\n",
        "    test_dataset = df_to_dataset(test_df, tokenizer, batch_size)\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset"
      ],
      "metadata": {
        "id": "FMWLU0Ra28ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, val_ds, test_ds = create_train_val_test_datasets(df, dummy_tokenizer, batch_size=8)"
      ],
      "metadata": {
        "id": "o6YDjrYH3Fku"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}